---
title: "trading jpm, wfc using tech rules"
author: "Michael Downs"
date: "July 24, 2015"
output: pdf_document
---

## summary
The report below explores a range of univariate, bivariate and trivariate strategies for SPY, JPM and WFC for the period of March 2010 to April 2015. Results were best for univariate, technical analysis models owing to their comparative ease of implementation. Momentum and Oscillator (RSI) strategies performed the best from both PNL and performance ratio perspectives. Performance of bivariate models lagged in these tests. However, Anatolyev and Gospodinov's decomposition model showed potential. While only the direction component was implemented here, it showed strong early performance suggesting that the full model would perform well. Finally, the trivariate model performed near the top overall in terms of both PNL and ratio scores.

**recommendation:** Based on these results, the best way to trade SPY, JPM and WFC for profit would be to:

**1. stack-univariate models.** Momentum and RSI did well individually. Stacking the combination via regression or other means will likely improve results as, to some extent, the two approaches make mistakes differently.

**2. introduce multi-variate signal.** There are two dimensions to this point. First, logistic regression, quadratic discriminant analysis or other classification tool can be used to incorporate a wider range of non-price variables into an up/down prediction. Those predictions can then be used to augment the stacked-univariate models above. Second, the trivariate model not only brought in more signal in the form of correlated stock moves, but it also expanded the range of trading options.

## setup
Before starting the problems, I'll make brief comments about the data and introduce common functions used later. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='hide',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}
library(highfrequency)
library(timeDate)
library(TTR)
library(tseries)
library(xts)
library(quantmod)
library(PerformanceAnalytics)
library(caret)
library(fUnitRoots)
library(urca)
library(lubridate)
library(mondate)
library(MTS)
library(timeSeries)
library(car)

setwd("~/Documents/Pers/Ed/Courses/stats242/homework")
price=read.csv("Bankdata.csv",colClasses=c("character","numeric","numeric","numeric"))
price[nchar(price[,1])==7,1]=paste0("0",price[nchar(price[,1])==7,1])
price[,1]=as.Date(price[,1],format="%m%d%Y")
price=as.xts(price[,-1],price[,1])
rtrn=diff(log(price))

# intialize global variables
rf=0.03
rf_t=0.0001173 # based on 252 NYSE trading days / year i.e., 1.0001173^252=1.03
bp=0.0001

```

### evaluate stationarity
While the price series is not stationary, the simple and log returns are stationary as evidenced by the auto and partial correlation (acf()/pacf()) graphics below. Augmented Dickey-Fuller test for the presence of a unit root ($\rho=1$) is accepted indicating the price series is non-stationary (0.1+ p-value) and rejected for the return series (p-values < 0.01). Those findings are corroborated by KPSS. These results suggest using either simple or log return can be used for calculating the investment performance ratios. Both results appear in the table below.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=6}

par(mfrow=c(3,2))
pacf(price$JPM);pacf(price$WFC)
pacf(diff(price$JPM)[-1]);pacf(diff(price$WFC)[-1])
pacf(diff(log(price$JPM))[-1]);pacf(diff(log(price$WFC))[-1])

```

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

test_stationarity=function(x,axis=NA){
     library(fUnitRoots)
     library(urca)
     result=as.data.frame(matrix(NA,length(x),7))
     names(result)=c("period","test type","adf pval","adf result",
                     "test type","kpss pval","kpss result")
     j=1
     for(i in 1:length(x)){
          result[j,1]=axis[i]
          result[j,2]="root"
          result[j,3]=adfTest(as.numeric(x[[i]]),lags=12,type="ct")@test$p.value
          result[j,4]=if(result[j,3]<0.1){"stationary"}else{"not"}
          result[j,5]="trend"
          tmp=ur.kpss(as.numeric(x[[i]]),lags="long",type="tau")
          result[j,6]=tmp@teststat
          result[j,7]=if(result[j,6]<tmp@cval[2]){"stationary"}else{"not"}
          j=j+1
     }
     return(result)
}

test_stationarity(list(as.numeric(price$JPM),as.numeric(price$WFC)),c("JPM","WFC"))
test_stationarity(list(diff(price$JPM),diff(price$WFC)),c("JPM","WFC"))
test_stationarity(list(diff(log(price$JPM)),diff(log(price$WFC))),c("JPM","WFC"))

```

### establish buy/hold benchmark
The first function in the code submission tracks performance of the "buy and hold" strategy which is used as benchmark for each of the portfolios below. The graphic below shows this performance for WFC, JPM and a 50/50 portfolio of each. This function will be used for a variety of date ranges. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='hold',fig.height=4,fig.width=7}

calc_bh=function(x,amt,type="diff(log)"){
     z=as.numeric(x)
     if(type=="diff(log)"){z=diff(log(z))}
     else if(type=="diff()"){z=diff(z)}
     rslt=rep(0,dim(x)[1]);rslt[1]=amt
     for(i in 1:length(z)){
          rslt[i+1]=rslt[i]*(1+z[i])
     }
     rslt=reclass(rslt,x)
     return(rslt)
}

wfc.t1.bh=calc_bh(price$WFC,1000,"diff(log)")
jpm.t1.bh=calc_bh(price$JPM,1000,"diff(log)")
port.t1.bh=calc_bh(price$WFC,500,"diff(log)")+calc_bh(price$JPM,500,"diff(log)")

par(mfrow=c(1,1))
plot(port.t1.bh,main="buy and hold",ylim=range(rbind(port.t1.bh,jpm.t1.bh,wfc.t1.bh)))
lines(jpm.t1.bh,col="blue")
lines(wfc.t1.bh,col="darkgreen")
legend("topleft",legend=c("wfc","50/50","jpm"),lwd=2,cex=1,col=c("darkgreen","black","blue"))
```

### calculate investment ratios
The second function in the code submission centralizes calculation of investment performance measures into a single function. Putting all funcions in a single container requires input values be standardized. **The analysis that follows will use $log(diff(price))$ as a measure of return. As a result, some of these ratios will differ from values commonly seen externally. However, their ability discern relative performance of the portfolios herein is maintained.** The output below shows the initail values for WFC and JPM.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

calc_ratios=function(ra,rb,rf){
     result=rbind(SharpeRatio(ra,rf,p=0.95,FUN="StdDev",weights=NULL,annualize=FALSE), 
                  TreynorRatio(ra,rb,rf,scale=252,modified = FALSE), 
                  SortinoRatio(ra,rf,weights=NULL),
                  CalmarRatio(ra,scale=252),
                  InformationRatio(ra,rb,scale=252))
     rownames(result)=c("sharpe","treynor","sortino","calmar","information")
     return(result)
}

calc_ratios(diff(log(price[,2:3]))[-1],diff(log(price[,1]))[-1],rf_t)

```

### generate return graphics
The third common function in the code submission standardizes output including graphics and performance metrics for each portfolio ensuring easy comparison.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='hold',fig.height=4,fig.width=7}

gen_returns=function(price,all.plot,start.date,end.date){
     
     # format graphics
     dir.joint.pnl=(all.plot$p1pnl+all.plot$p2pnl)[-c(1,dim(all.plot)[1])]
     par(mfcol=c(3,1))
     plot((all.plot$p1states+all.plot$p2states),main="States (100=long) (-100=short)",type="l",col="blue")
     plot((all.plot$p1cash+all.plot$p2cash)[-c(1,dim(all.plot)[1])],main="Cash",type="l",col="blue")

     a=length(price$WFC[paste0(start.date,"/",end.date)])
     bh=as.numeric(calc_bh(price$WFC[paste0(start.date,"/",end.date)][-c(1,a)],500,"diff(log)")+
                        calc_bh(price$JPM[paste0(start.date,"/",end.date)][-c(1,a)],500,"diff(log)"))
     plot(dir.joint.pnl,main="PNL",type="l",col="blue",ylim=range(cbind(bh,dir.joint.pnl)))
     lines(bh,col="red")
     legend("topleft",legend=c("buy-hold 50/50","portfolio"),lwd=2,cex=1,col=c("red","blue"))
     
     # format performance stats
     rtrn.5050=diff(log(price$WFC[paste0(start.date,"/",end.date)][-c(1:2,a)]))+
          diff(log(price$JPM[paste0(start.date,"/",end.date)][-c(1:2,a)]))
     rtrn.spy=diff(log(price$SPY[paste0(start.date,"/",end.date)][-c(1:2,a)]))
     rtrn.port=diff(log(dir.joint.pnl))
     rtrn.port=sapply(rtrn.port, function(x) replace(x, is.infinite(x),NA))
     rtrn.port=as.xts(rtrn.port,index(price[paste0(start.date,"/",end.date)][-c(1:2,a)]))
     merged=merge(rtrn.port,rtrn.5050,rtrn.spy)[-1];names(merged)=c("portfolio","buy-hold","spy")
     
     # pnl summary
     #print("pnl summary:")
     port.val=round(dir.joint.pnl[length(dir.joint.pnl)])
     port.v.bh=round(dir.joint.pnl[length(dir.joint.pnl)]-bh[length(bh)])
     port.ratios=calc_ratios(merged[,1],merged[,3],rf_t)
     bh.ratios=calc_ratios(merged[,2],merged[,3],rf_t)
     rslt=list(port.val=port.val,port.v.bh=port.v.bh,port.ratios=port.ratios,bh.ratios=bh.ratios)
     return(rslt)    
}

```

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='hide',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

plot_series=function(series1,s1ab1=0,s1ab2=0,s1main=NULL,series2=NULL,s2ab1=0,s2ab2=0,s2main=NULL){
     series1=as.data.frame(series1)
     if(!is.null(series2)){
          par(mfrow=c(2,1))
          series2=as.data.frame(series2)
          }else{par(mfrow=c(1,1))}
          
     if(dim(series1)[2]>1){
          plot(series1[,1],type="l",main=s1main,ylim=range(rbind(series1[,1],series1[,2])))
          lines(series1[,2],col="red")
     } else{
          plot(series1[,1],type="l",main=s1main)
     }
     if(s1ab1>0){abline(h=s1ab1,col="blue")}
     if(s1ab2>0){abline(h=s1ab2,col="blue")}
     
     if(!is.null(series2)){
          if(dim(series2)[2]>1){
               plot(series2[,1],type="l",main=s2main,ylim=range(rbind(series2[,1],series2[,2])))
               lines(series2[,2],col="red")
          } else{
               plot(series2[,1],type="l",main=s2main)
          }
          if(s2ab1>0){abline(h=s2ab1,col="blue")}
          if(s2ab2>0){abline(h=s2ab2,col="blue")}
     }
}

```

### set date
Finally, the fourth common function ensures apples to apples portfolio performance comparisons by setting the date range for all portfolios to the period between July 1 2010 to Feb 28 2015. This allows a three-month lookback for problem 3. Note, however, that in that problem I found better performance with different lookback periods.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='hide',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

start.date=as.Date("2010-07-01")
end.date=as.Date("2015-02-28")

```

## problem 1
### a. moving average trading rules
#### rule 1: time / weights
I implemented the $ma_t=\frac{1}{L}\sum_{i=0}^{L-1} p_{t-1}$ strategy selling when $p_t>\omega*ma_t$ and buying if $p_t<\frac{1}{\omega}*ma_t$. In this case and all subsequent cases, I used grid search to find the better vaues for $\omega$ and $L$. In this section, I searched over a ranges of moving average "lags", $\omega$ values and holding periods for the optimal combination given the data. I evaluate the strategy below. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

gen_ma_w=function(m,l=NULL,w=NULL,h=NULL,rslt="pnl"){
     if(is.null(l)){l=seq(2,10,1)}
     if(is.null(w)){w=seq(0.95,1.1,0.02)}
     if(is.null(h)){h=seq(1,2,1)}
     amt=100
     
     for(i in 1:length(l)){
          for(j in 1:length(w)){
               for(k in 1:length(h)){
                    gl=ma_w(m[,1],l[i],w[j],h[k],amt,rslt)
                    rslt=cbind(l[i],w[j],h[k],gl)
                    if(exists("mstr")){mstr=rbind(mstr,rslt)}else{mstr=rslt}
               }
          }
     }
     return(mstr)
}

ma_w=function(ARseries,l,w,h,amount,rslt){
     rtrn=as.data.frame(coredata(ARseries))
     rtrn$states=0
     rtrn$PNL=0
     rtrn$cash=0
     rtrn$trades=0
    
    isAroundMean <- 1
    for (i in l:dim(rtrn)[1]){
         mu=mean(ARseries[(i-(l-1)):i])

         score=0
         if(ARseries[i]>(mu*w)) score=-1
         else if(ARseries[i]<((1/w)*mu)) score=1

        #3 conditions of whether to trade or not
        if (i > l){rtrn$states[i]=rtrn$states[i-1]}
        if (isAroundMean && (i==l||rtrn$states[i-1]==0)) {
            if (abs(score) == 1) rtrn$trades[i]=1
            if (score == 1) rtrn$states[i]=amount
            else if (score == -1) rtrn$states[i]=-amount
          }
        else if (rtrn$states[i-h]!=0){
              if(abs(score)!=1){
                   rtrn$trades[i]=1
                   rtrn$states[i]=0
              }
         }
        #update cash and PNL
        if (i==l) rtrn$cash[i] <- 500 - ARseries[i] * rtrn$states[i]
        else rtrn$cash[i] <- rtrn$cash[i-1] - ARseries[i] * (rtrn$states[i] - rtrn$states[i-1])
        rtrn$PNL[i] <- rtrn$cash[i] + rtrn$states[i] * ARseries[i]
        if (abs(score) <= 1) isAroundMean <- 1
        else isAroundMean <- 0
    }
    if(rslt=="plot"){
         return(rtrn)
    }
    else{
         return(rtrn$PNL[i])
    }
}


```

**1. trade entry:** Deviation from the $\mu$ of moving average price drove trade initiation. wfc showed reasonable results for lags between 3 and 10. jpm's best results occurred for a lag of 6. In both cases, wt or $\omega$ of 1.1. These relatively tight windows resulted in frequent trading of about one trade every 3.5 days (341 total jpm trades, 326 total wfc trades).

**2. trade exit:** Most trades were closed out in one day. However, both models did best when max holding period increased to 2 such that, if current price was still +/- $\omega*\mu_{lag period}$, the positon was held for another day. The graphics below show long/short positioning, cash balance and pnl vs. benchmark.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}
#jpm.ma=gen_ma_w(price$JPM[paste0(start.date,"/",end.date)])
#jpm.bst=jpm.ma[which.max(jpm.ma[,4]),];jpm.bst #ma=6, w=1.01, h=2, pnl=1802
jpm.ma=ma_w(price$JPM[paste0(start.date,"/",end.date)],l=6,w=1.01,h=2,100,rslt="plot")
names(jpm.ma)=c("JPM","p1states","p1pnl","p1cash","p1trades")

#wfc.ma=gen_ma_w(price$WFC)[paste0(start.date,"/",end.date)]
#wfc.bst=wfc.ma[which.max(wfc.ma[,4]),];wfc.bst #ma=10, w=1.01, h=1, pnl=4694 (wha?)
wfc.ma=ma_w(price$WFC[paste0(start.date,"/",end.date)],l=3,w=1.01,h=2,100,rslt="plot")
names(wfc.ma)=c("WFC","p2states","p2pnl","p2cash","p2trades")

rslt=gen_returns(price,cbind(jpm.ma,wfc.ma),start.date,end.date)
print(rslt$port.val);print(rslt$port.v.bh)
#sum(jpm.ma$p1trades);sum(wfc.ma$p2trades)
 
```

**3. results (pnl):** Moving average was an effective strategy from a pnl perspective grossing $4,040, $2,177 greater than the buy-and-hold strategy.   

**4. results (performance ratios):** The relative performance ratios below highlight a couple points. First, while sharpe improved, treynor significantly improved. Given that treynor uses $\beta_p$ in the denominator and sharpe uses $\sigma_p$, the difference suggests, the portfolio provided better returns  while reducing correlation with the market. A significant improvement in calmar reflects the increased compound return relative to the maximum drawdown. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

print(rslt$port.ratios);print(rslt$bh.ratios)

```
**5. interpretation:** The plots below break-out the portfolio performance by sub-model (i.e., jpm, wfc). Note the early outperformance outperformance of the jpm model. As variance dies down and the upward trend is established, the the jpm 6-day lag MA becomes less effective. While one might conclude that MA may be best in more highly variable, sideways-moving markets. This result suggests that using a sliding window to dynamically adjust lag, $\omega$ and window may further optimize this strategy.  

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=5,fig.width=7}
par(mfcol=c(2,2))
plot(jpm.ma$JPM,type="l",main="jpm price")
plot(jpm.ma$p1pnl,type="l",main="ma portfolio jpm performance")
plot(wfc.ma$WFC,type="l",main="wfc price")
plot(wfc.ma$p2pnl,type="l",main="ma portfolio wfc performance")
```

#### rule 2: momentum
In this section I copute moving averages over ranges of short- and long-term lags seeking the optimal combination for each of the JPM and WFC price series finding the optimal lags for the short- and long-term moving averages. I evaluate this strategy below. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

gen_ma_sl=function(m,lng=NULL,shrt=NULL,rslt="pnl"){
     if(is.null(lng)){lng=seq(15,30,1)}
     if(is.null(shrt)){shrt=seq(2,10,1)}
     amt=100
     
     for(i in 1:length(lng)){
          for(j in 1:length(shrt)){
                    gl=ma_sl(m[,1],lng[i],shrt[j],amt,rslt)
                    rslt=cbind(lng[i],shrt[j],gl)
                    if(exists("mstr")){mstr=rbind(mstr,rslt)}else{mstr=rslt}               
          }
     }
     return(mstr)
}

ma_sl=function(ARseries,lng,shrt,amount,rslt="pnl"){
     
     lngth=length(ARseries)
     relation=rep(0,lngth)
     trades=0
     states=rep(0,lngth)
     PNL=rep(0,lngth)
     cash=rep(0,lngth)
    
    isAroundMean <- 1
    for (i in 1:lngth){
         if(i<lng){lng.mu=mean(ARseries[1:i])}
         else{lng.mu=mean(ARseries[(i-(lng-1)):i])}
         
         if(i<shrt){shrt.mu=mean(ARseries[1:i])}
         else{shrt.mu=mean(ARseries[(i-(shrt-1)):i])}
         
         if(shrt.mu>=lng.mu){relation[i]=-1}else{relation[i]=1}
         
         score=0
         if(i>1){
              if(relation[i]+relation[i-1]==0){
                   if(relation[i]==-1){score=-1}
                   if(relation[i]==1){score=1}
               }
         }
         
        #3 conditions of whether to trade or not
        if (i > 1){states[i]=states[i-1]}
        if (isAroundMean && (i==1||states[i-1]==0)) {
            if (abs(score) == 1) trades=trades+1
            if (score == 1) states[i]=amount
            else if (score == -1) states[i]=-amount
          }
         else if (states[i-1]!=0){
              trades=trades+1
              states[i]=0
         }
       
        #update cash and PNL
        if (i==1) cash[i] <- 500 - ARseries[i] * states[i]
        else cash[i] <- cash[i-1] - ARseries[i] * (states[i] - states[i-1])
        PNL[i] <- cash[i] + states[i] * ARseries[i]
        if (abs(score) <= 1) isAroundMean <- 1
        else isAroundMean <- 0
    }
    if(rslt=="plot"){
         list(ARseries = ARseries, trades = trades, 
              states = states, cash = cash, PNL = PNL)
    }
    else{
         return(PNL[i])
    }
}
```

**1. trade entry:** Crossing long- and short-term moving avergaes drove trading. WFC's best results came with 22-day long moving average and 7-day short. JPM's best results came with 19-day long and 9 day short. These relatively long windows resuted in less-frequent trading. tight windows resulted in frequent trading of about one trade in each holding every 9.5 days (130 total JPM trades, 118 total WFC trades).

**2. trade exit:** Trades were closed out daily. The graphics below show long/short positioning, cash balance and pnl vs. benchmark.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

#jpm.ma.sl=gen_ma_sl(price$JPM);jpm.sl.bst=jpm.ma.sl[which.max(jpm.ma.sl[,3]),];jpm.sl.bst
jpm.ma.sl=ma_sl(price$JPM[paste0(start.date,"/",end.date)],lng=19,shrt=9,100,rslt="plot")
jpm.ma.sl=as.data.frame(cbind(jpm.ma.sl$states,jpm.ma.sl$cash,jpm.ma.sl$PNL));
names(jpm.ma.sl)=c("p1states","p1cash","p1pnl")
# trades: 130

#wfc.ma.sl=gen_ma_sl(price$WFC);wfc.sl.bst=wfc.ma.sl[which.max(wfc.ma.sl[,3]),];wfc.sl.bst
wfc.ma.sl=ma_sl(price$WFC[paste0(start.date,"/",end.date)],lng=22,shrt=7,100,rslt="plot")
wfc.ma.sl=as.data.frame(cbind(wfc.ma.sl$states,wfc.ma.sl$cash,wfc.ma.sl$PNL));
names(wfc.ma.sl)=c("p2states","p2cash","p2pnl")
# trades: 118

rslt=gen_returns(price,cbind(jpm.ma.sl,wfc.ma.sl),start.date,end.date)
print(rslt$port.val);print(rslt$port.v.bh)
```

**3. results (pnl):** Momentum was an effective strategy from a pnl perspective grossing $2,844, $981 over the buy and hold strategy. 

**4. results (performance ratios):** As with moving average, momentum improved sharpe, treynor and calmar ratios. Momentum also showed a near doubling of information and sortino ratios. The information inprovement reflects greater consistency in returns (reduced tracking error i.e. sd $r_p-r_b$). The sortino improvement reflexts lower downside volatility. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

print(rslt$port.ratios);print(rslt$bh.ratios)

```
**5. interpretation:** Unlike moving average, momentum showed strong performance throughout the five year period. However, like moving average performance plateaued in the later periods allowing the market to catch up. This suggests that dynamically adjusting long and short moving average lags may imporove performance. 

#### rule 3: bollinger bands
The code for this section defines $\bar{P}_t^{(L)}$, $\hat{P}_t^{(L)}$ and $\sigma_t^{(L)}$. It defines Bollinger Bands at $\hat{P}_t^{(L)} +/- 2]sigma_t^{(L)}$. The grid search here is used to vary the lookback period for the mean calculation and the holding period for trades.
```{r eval=FALSE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

library(TTR)

gen_ma_bb=function(m){
     l=seq(15,30,1) # lookback
     h=seq(2,5,1) # holding period
     amt=100
     for(i in 1:length(l)){
          for(j in 1:length(h)){
               gl=ma_bb(m[,1],l[i],h[j],amt,"pnl")
               rslt=cbind(l[i],h[j],gl)
               if(exists("mstr")){mstr=rbind(mstr,rslt)}else{mstr=rslt}
          }
     }
     return(mstr)
}

ma_bb=function(ARseries,l,h,amount,rslt="pnl"){
     length=length(ARseries)
     #price=ARseries[l:length,]
    trades=0
    states=rep(0, length)
    PNL=rep(0, length)
    cash=rep(0, length)
    
    isAroundMean <- 1
    for (i in 1:length){
         if(i<l){p.bar=mean(ARseries[1:i])}
         else{p.bar=mean(ARseries[(i-(l-1)):i])}
         
         if(i<l){
              a=ARseries[1:i]
              b=(seq(i,1,-1))^-1
              p.hat=sum((a*b)/sum(b))
              sigma=1
          }else{
               a=ARseries[(i-(l-1)):i]
               b=(seq(l,1,-1))^-1
               p.hat=sum((a*b)/sum(b))
               sigma=(1/(l-1)*(sum((ARseries[(i-(l-1)):i]-p.bar)^2)))^(1/2)
          }
         band.upper=p.hat+2*sigma
         band.lower=p.hat-2*sigma
         
         score=0
         if(ARseries[i]>band.upper) score=-1
         else if(ARseries[i]<band.lower) score=1
         
        #3 conditions of whether to trade or not
        if (i > 1){states[i]=states[i-1]}
        if (isAroundMean && (i==1||states[i-1]==0)) {
            if (abs(score) == 1) trades=trades+1
            if (score == 1) states[i]=amount
            else if (score == -1) states[i]=-amount
          }
         else if (states[i-h]!=0){
              if(abs(score)!=1){
                   trades=trades+1
                   states[i]=0
              }
         }
       
        #update cash and PNL
        if (i==1) cash[i] <- 500 - ARseries[i] * states[i]
        else cash[i] <- cash[i-1] - ARseries[i] * (states[i] - states[i-1])
        PNL[i] <- cash[i] + states[i] * ARseries[i]
        if (abs(score) <= 1) isAroundMean <- 1
        else isAroundMean <- 0
    }
    if(rslt=="plot"){
         list(ARseries = ARseries, trades = trades, states = states, cash = cash, PNL = PNL)
    }
    else{
         return(PNL[i])
    }
}

```

**1. trade entry:** Trades are initiated when $p_t$ crosses one of the two Bollinger bands. When $p_t$ dips below, it goes long. When $p_t$ goes above, it goes short. JPM's best results came with a lagged mean calculation over 25 periods. WFC's best results came with a lagged mean over 21 periods. 

**2. trade exit:**  While both models did better with longer holding period settings, the graphics below show that most trades were closed in about 1 day. JPM traded 14 times. WFC traded 16 times. The graphics below show long/short positioning, cash balance and pnl vs. benchmark.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}
#plot(price$JPM,ylim=c(20,70))
#lines(BBands(price$JPM,n=20,sd=2)$up,col="red")
#lines(BBands(price$JPM,n=20,sd=2)$dn,col="red")

#jpm.ma.bb=gen_ma_bb(price$JPM);jpm.bst.bb=jpm.ma.bb[which.max(jpm.ma.bb[,3]),];jpm.bst.bb
jpm.ma.bb=ma_bb(price$JPM[paste0(start.date,"/",end.date)],l=25,h=3,100,rslt="plot")
jpm.ma.bb=as.data.frame(cbind(jpm.ma.bb$states,jpm.ma.bb$cash,jpm.ma.bb$PNL));
names(jpm.ma.bb)=c("p1states","p1cash","p1pnl")

#wfc.ma.bb=gen_ma_bb(price$WFC);wfc.bst.bb=wfc.ma.bb[which.max(wfc.ma.bb[,3]),];wfc.bst.bb
wfc.ma.bb=ma_bb(price$WFC[paste0(start.date,"/",end.date)],l=21,h=3,100,rslt="plot")
wfc.ma.bb=as.data.frame(cbind(wfc.ma.bb$states,wfc.ma.bb$cash,wfc.ma.bb$PNL));
names(wfc.ma.bb)=c("p2states","p2cash","p2pnl")

rslt=gen_returns(price,cbind(jpm.ma.bb,wfc.ma.bb),start.date,end.date)
print(rslt$port.val);print(rslt$port.v.bh)
```

**3. results (pnl):** Bollinger was a less effective strategy from a pnl perspective grossing $2,308, $445 over the buy and hold strategy. **Note: the portfolio performance graphic above sometimes works, sometimes doesn't.**

**4. results (performance ratios):** Bollinger model ratio performance was generally inferior to a buy-and-hold strategy.  

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

print(rslt$port.ratios);print(rslt$bh.ratios)

```
**5. interpretation:** This implementation of Bollinger is dynamically calculating bands based on lagged means and standard deviations. Given that the benefit of Bollinger bands over moving average approaches is the incorporation of variability, it could be further improved by testing over a range of standard deviation multipliers as 2 standard deviations appears too stringent for all windows. 

### 1b oscillator rule
This section defines the relative strength index ($RSI_t$) and the cumulative upward ($U_t$) and downward ($D_t$) moves for a range of periods. It then grid searches over a range of lookback and maximum holding periods. I review results below. 
```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

gen_osc=function(m){
     l=seq(3,12,1) # lookback
     h=seq(1,2,1) # holding period
     amt=100
     for(i in 1:length(l)){
          for(j in 1:length(h)){
               gl=osc(m[,1],l[i],h[j],amt,"pnl")
               rslt=cbind(l[i],h[j],gl)
               if(exists("mstr")){mstr=rbind(mstr,rslt)}else{mstr=rslt}
          }
     }
     return(mstr)
}

osc=function(ARseries,l,h,amount,rslt="pnl"){
     length=length(ARseries)
    trades=0
    states=rep(0, length)
    PNL=rep(0, length)
    cash=rep(0, length)
    
    isAroundMean <- 1
    for (i in 1:length){
         if(i<l){rsi=50}
         else{       
              up=sum((as.numeric(ARseries[(i-(l-1)):i])-
                           as.numeric(ARseries[(i-l):(i-1)]))>0)/l
              
              dn=sum((as.numeric(ARseries[(i-(l-1)):i])-
                           as.numeric(ARseries[(i-l):(i-1)]))<0)/l
              rsi=100*(up/(up+dn))
          }
         
         score=0
         if(rsi>70){score=-1}
         else if(rsi<30){score=1}
         
        #3 conditions of whether to trade or not
        if (i > 1){states[i]=states[i-1]}
        if (isAroundMean && (i==1||states[i-1]==0)) {
            if (abs(score) == 1) trades=trades+1
            if (score == 1) states[i]=amount
            else if (score == -1) states[i]=-amount
          }
         else if (states[i-h]!=0){
              if(abs(score)!=1){
                   trades=trades+1
                   states[i]=0
              }
         }
       
        #update cash and PNL
        if (i==1) cash[i] <- 500 - ARseries[i] * states[i]
        else cash[i] <- cash[i-1] - ARseries[i] * (states[i] - states[i-1])
        PNL[i] <- cash[i] + states[i] * ARseries[i]
        if (abs(score) <= 1) isAroundMean <- 1
        else isAroundMean <- 0
    }
    if(rslt=="plot"){
         list(ARseries = ARseries, trades = trades, states = states, cash = cash, PNL = PNL)
    }
    else{
         return(PNL[i])
    }
}
```

**1. trade entry:** Trades are initiated when $RSI_t$ crosses the upper (70) or lower (30) bound. When $RSI_t$ dips below, it goes long. When $RSI_t$ goes above, it goes short. jpm's best results came with a lagged RSI calculation over 5 periods. WFC's best results came with a lagged mean over 7 periods. 

**2. trade exit:**  Trades were exited either when the RSI moved inside the relevant band or at the end of the holding period. The graphics below show that most trades were closed in about 1 day. JPM traded 322 times. WFC traded 266 times. WFC's longer optimal lag and lower trading volume reflect less volatility in the series. The graphics below show long/short positioning, cash balance and pnl vs. benchmark.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}
#plot(price$JPM,ylim=c(20,70))
#lines(BBands(price$JPM,n=20,sd=2)$up,col="red")
#lines(BBands(price$JPM,n=20,sd=2)$dn,col="red")

#jpm.osc=gen_osc(price$JPM);jpm.bst.osc=jpm.osc[which.max(jpm.osc[,3]),];jpm.bst.osc
jpm.osc=osc(price$JPM[paste0(start.date,"/",end.date)],l=5,h=1,100,rslt="plot")
jpm.osc=as.data.frame(cbind(jpm.osc$states,jpm.osc$cash,jpm.osc$PNL))
names(jpm.osc)=c("p1states","p1cash","p1pnl") #322 trades

#wfc.osc=gen_osc(price$WFC);wfc.bst.osc=wfc.osc[which.max(wfc.osc[,3]),];wfc.bst.osc
wfc.osc=osc(price$WFC[paste0(start.date,"/",end.date)],l=7,h=1,100,rslt="plot")
wfc.osc=as.data.frame(cbind(wfc.osc$states,wfc.osc$cash,wfc.osc$PNL))
names(wfc.osc)=c("p2states","p2cash","p2pnl") #266 trades

rslt=gen_returns(price,cbind(jpm.osc,wfc.osc),start.date,end.date)
print(rslt$port.val);print(rslt$port.v.bh)
```

**3. results (pnl):** Oscillator was an effective startegy from a pnl perspective grossing $4,434, $2,471 over the buy and hold strategy.

**4. results (performance ratios):** Oscillator rule did not score well on portfolio performance ratios. I attribute this more to a coding error that introduced NaN's than poor performance of the algorithim.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

print(rslt$port.ratios);print(rslt$bh.ratios)

```

## problem 2

This section implements the "direction" component of Anatolyev and Gospodinov's 2010 model decomposing the return $r_t$. Specifcally, it performs logistic regression on lagged prices (and price changes) to predict whether future chnages will be positive (or negative) in excess of transaction costs. It then searches over a grid of lags, probability thresholds and holding periods for the optimal model.
```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

gen_direct=function(m){
     cst=c(0.001) # cost
     lag=seq(2,5,1) # lag
     thr=seq(1.8,2.1,0.1) # threshold
     h=seq(1,1,1) # holding period
     amt=100
     for(i in 1:length(lag)){
          for(j in 1:length(thr)){
               for(k in 1:length(h)){
                    gl=direct(m[,1],lag[i],thr[j],h[k],amt,"pnl",cst)
                    rslt=cbind(lag[i],thr[j],h[j],cst,gl)
                    if(exists("mstr")){mstr=rbind(mstr,rslt)}else{mstr=rslt}
               }
          }
     }
     return(mstr)
}

direct=function(x,l,thr,h,amt,rslt="pnl",cst=0){
     
    # format x and y
    x$diffs=as.numeric(diff(x));x=x[-1]
    x$costs=x[,1]*cst
    x$class=0;x$class[(x$diffs-x$costs)>0]=1
    lags=as.data.frame(matrix(0,dim(x)[1],l));lag.ids=NULL
    for(i in 1:l){
         lag.ids[i]=sprintf("lag%i",i)
         lags[(i+1):dim(lags)[1],i]=x[1:(dim(x)[1]-i),1]
    }
    names(lags)=lag.ids
    lags=as.xts(lags, index(x))
    x=cbind(x,lags);x=as.data.frame(coredata(x))
    
    trades=0;start=max(h,2,l+1);x=coredata(x)
    x$upProb=0;x$dnProb=0;x$pred=NA;x$score=0
    x$states=0;x$cash=0;x$PNL=0;x$trades=0
    for(i in 1:dim(x)[2]){x[,i]=as.numeric(x[,i])}
    
    for (i in start:(dim(x)[1]-1)){
         glm.fit=glm(as.factor(x$class[1:(i-1)])~.,
                     data=x[1:(i-1),5:(5+(l-1))],family="binomial")
         x$upProb[i]=predict(glm.fit,x[i,5:(5+(l-1))],type="response")
         
         if(i<23){incr=0.5}else{incr=thr*sd(x$upProb[(i-22):(i-1)])}
         if(x$upProb[i]>(0.5+incr)){x$score[i]=1;x$pred[i]=1}
         else if(x$upProb[i]<(0.5-incr)){x$score[i]=-1;x$pred[i]=0}
         
        #3 conditions of whether to trade or not
        if (i==start){x$states[i]=x$states[i-1]}
        else if (x$states[i-1]==0) {
            if (abs(x$score[i])==1){x$trades[i]=1}
            if (x$score[i]==1){x$states[i]=-amt}
            else if (x$score[i]==-1){x$states[i]=amt}
          }
        else if (x$states[i-1]!=0){
              x$trades[i]=1
              if(x$score[i]==1&&x$score[i-1]==1){x$states[i]=x$states[i-1]}
              else if(x$score[i]==-1&&x$score[i-1]==-1){x$states[i]=x$states[i-1]}
              else{x$states[i]=0}
         }
        #update cash and PNL
        if(i==start){x$cash[i]=500}
        else{x$cash[i]=x$cash[i-1]-((1-cst)*(x[i,1]*(x$states[i]-x$states[i-1])))}
        x$PNL[i]=x$cash[i]+x$states[i]*x[i,1]
    }
    #good=!is.na(x$pred)
    #print(confusionMatrix(x$pred[good],x$class[good]))
    # return results
    if(rslt=="full"){
         return(x)
    }
    else{
         return(x$PNL[i])
    }
}

```
 
```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

#plot_results=function(x){
#     par(mfcol=c(3,1))
#     #plot(x[,1],type="l",col="blue",main="Price Series") # hmmm.... seems this is what we could run ratios on. 
#     # plot return series
#     plot(x$states,main="States (100=long) (-100=short)",type="l",col="blue")
#     plot(x$cash,main="Cash",type="l",col="blue")
#     plot(x$PNL,main="PNL",type="l",col="blue")
#}

#jpm.direct=gen_direct(price$JPM)
#jpm.bst.direct=jpm.direct[which.max(jpm.direct[,5]),];jpm.bst.direct #l=5, t=1.8, h=1, 
jpm.plot=direct(price$JPM[paste0(start.date-1,"/",end.date)],5,1.8,1,100,"full",0.001)

#wfc.direct=gen_direct(price$WFC)
#wfc.bst.direct=wfc.direct[which.max(wfc.direct[,5]),];wfc.bst.direct #l=5, t=1.9, h=1, gl=1885
wfc.plot=direct(price$WFC[paste0(start.date-1,"/",end.date)],5,1.9,1,100,"full",0.001)

# portfolio returns
#port.rtrn=diff(jpm.plot$PNL+wfc.plot$PNL+0.00001)
#port.rtrn=diff(log(jpm.plot$PNL+wfc.plot$PNL+0.0000001))
#port.rtrn=as.xts(raw.rtrn,index(price)[-c(1:2)])
#merged=merge(port.rtrn,diff(log(price[,1])));merged=merged[8:1257]
#merged=merge(port.rtrn,diff(price[,1]));merged=merged[8:1257]
#direct_ratios=calc_ratios(merged[,1],merged[,2],rf_t)

# show sensitivities like p64 of notes
# final should mention stacked indicator. maybe even test stacking predictions. could just slam them all together, train on priors, the forecast next day. does it beat logistic alone? 
# re-portolio construction, see p73 but gist: looked at variance-based allocation, but settled on simple average.
```

**1. trade entry:** Trades are initiated when logistic probabilities indicated a strong expectation that $p_{t+1}$ would be up or down in excess of trade costs. 

**2. trade exit:**  Trades were exited either when the probabilities changed signficantly or at the end of the holding period. This strategy traded frequently with 590 JPM trades and 467 WFC trades. The plots below show the resulting cash and pnl effects. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

pass=cbind(jpm.plot[,c(14:16)],wfc.plot[,c(14:16)])
names(pass)=c("p1states","p1cash","p1pnl","p2states","p2cash","p2pnl")
rslt=gen_returns(price,pass,start.date,end.date)
print(rslt$port.val);print(rslt$port.v.bh)
```

**3. results (pnl):** Anatolyev was a better trading rule than the final results indicate. While the final model grossed $2,179, $319 over buy-and-hold, earlier models grossed over $4,000.

**4. results (performance ratios):** The portfolio performance of this final model reflects the poor performance towards the end of the series. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

print(rslt$port.ratios);print(rslt$bh.ratios)

```

**5. interpretation:** Interestingly, the most accurate logistic models were not the best performers. Predictions in some models (net of probability thresholds) were 56\%+ accurate. However, these models traded infrequently and were not able to capitalize on the uptrend. That raises the important point of **overfitting the data**. As the amount of upticks in the training set increased, the model appeard to become biased towards upward predictions. To get this model to perform, one would have to find the optimal training set size and carefully manage the proportion of up and down ticks. The graphics below show how the algorithm dials-in with volume. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

par(mfrow=c(3,1))
plot(jpm.plot$upProb)
hist(jpm.plot$upProb[1:100],xlim=c(0,1))
abline(v=mean(jpm.plot$upProb[1:100]),col="red",lwd=3)
hist(jpm.plot$upProb[500:600],xlim=c(0,1))
abline(v=mean(jpm.plot$upProb[500:600]),col="red",lwd=3)

``` 

### problem 3
#### a. distance
This section implements both Gatev and Scruggs approaches to distance pairs trading. After testing both approaches, I settled on Scruggs method. This section iterates through data taking a lagged number of months, finding parity, then using deviation from that parity to drive trading. The grid search component varies over threshold numer of standard deviations, a regression or "retreat" value and a lookback period of months. 
```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='hide',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

monnb=function(d){lt=as.POSIXlt(as.Date(d,origin="1900-01-01"));lt$year*12+lt$mon}
# compute a month difference as a difference between two monnb's
mondf=function(d1,d2){monnb(d2)-monnb(d1)}
mnths=mondf(start.date,end.date)+1

gen_distance=function(vrs,m,start.date,mnths,output){
     
     cst=c(0.001) # cost
     thr=seq(1.7,1.7,0.2) # threshold
     reg=seq(0.5,0.5,0.2) # allowance for regression
     lag=seq(3,3,1)
     
     amt=50
     
     for(r in 1:length(reg)){
          for(k in 1:length(thr)){
               for(l in 1:length(lag)){
                    inv=process_days(vrs,m,start.date,mnths,lag[l])
                    gl=distance(inv,thr[k],reg[r],amt,output,cst) #"pnl", "full"
                    rslt=cbind(vrs,thr[k],reg[r],lag[l],cst,gl)
                    if(exists("mstr")){mstr=rbind(mstr,rslt)}else{mstr=rslt} 
               } 
          }
     }
     return(mstr)
}

process_days=function(vrs,m,start.date,mnths,lag){
       
     for(i in 1:mnths){
          cur.date=start.date; month(cur.date)=month(cur.date)+(i-1)
          lb.date=cur.date;month(lb.date)=month(lb.date)-lag
          inv.date=cur.date;month(inv.date)=month(inv.date)+1
          lb=m[paste0(lb.date,"/",cur.date-1)]
          inv=m[paste0(cur.date,"/",inv.date-1)]
                    
          inv=as.data.frame(coredata(inv))
          
          if(vrs=="a"){
               p.m.1.a=prod(1*(1+diff(log(lb[,1]))[-1])) 
               p.m.2.a=prod(1*(1+diff(log(lb[,2]))[-1]))
               p.dist.a=sum((p.m.1.a-p.m.2.a)^2)/dim(lb)[1]
               p.sd.a=sqrt(1/(dim(lb)[1]-1)*sum(((p.m.1.a-p.m.2.a)^2-p.dist.a)^2))
               p.1=p.2=NULL
               for(j in 2:dim(lb)[1]){
                    p.1[j]=prod(1*(1+(diff(log(lb[((j-1):j),1])))[2]))
                    p.2[j]=prod(1*(1+(diff(log(lb[((j-1):j),2])))[2]))
               }
               p.1=p.1[-1];p.2=p.2[-1]
          
               inv$adjP1=inv$adjP2=0
              for(k in 2:dim(inv)[1]){
                    inv$adjP1[k]=prod(1*(1+(diff(log(inv[((i-1):k),1])))))
                    inv$adjP2[k]=prod(1*(1+(diff(log(inv[((i-1):k),2])))))
               }
               inv$p12Dist=(inv$adjP1-inv$adjP2)^2
               inv$p12Sd=inv$p12Dist/p.sd.a
               inv=inv[-1,]
          }else if (vrs=="b"){
               mns=colMeans(lb)
               tgt.p=sum(mns)/2
               cum.factor.1=mns[1]/tgt.p;cum.factor.2=mns[2]/tgt.p
               lb.parity=(mns[1]/cum.factor.1)/(mns[2]/cum.factor.2)
               lb$adjP1=lb[,1]/cum.factor.1;lb$adjP2=lb[,2]/cum.factor.2
               lb$curPrty=lb$adjP1/lb$adjP2
               lb$dev=lb$curPrty-lb.parity
               p.sd.b=sd(lb$dev)# this is sd of price diff
          
               # calc deviations
               inv$adjP1=inv[,1]/cum.factor.1;inv$adjP2=inv[,2]/cum.factor.2
               inv$curPrty=inv$adjP1/inv$adjP2
               inv$dev=inv$curPrty-lb.parity
               inv$p12sd=abs(inv$dev)/p.sd.b
          }
          inv$p1states=0;inv$p2states=0;inv$p1cash=0;inv$p2cash=0;
          inv$p1pnl=0;inv$p2pnl=0;inv$trades=0
          for(l in 1:dim(inv)[2]){inv[,l]=as.numeric(inv[,l])}
          start=2;max.days=20
          
          if(exists("mstr")){mstr=rbind(mstr,inv)}else{mstr=inv}
     }
     plot_series(cbind(mstr$adjP1,mstr$adjP2),0,0,"adjusted price",
                      mstr$dev,0,0,"parity deviation")
     return(mstr)
}

distance=function(inv,thr,reg,amt,rslt="pnl",cst=0){
     start=2;max.days=20
     
     for (i in start:(dim(inv)[1]-1)){
          if (i==start){inv$p1states[i]=inv$p1states[i-1]}
          else if(inv$p1states[i-1]==0){
               if(inv$p12sd[i]>thr){
                    inv$trades[i]=2
                    #if((inv$adjP1[i]-inv$adjP1[i-2])>(inv$adjP2[i]-inv$adjP2[i-2])){
                    if(inv$adjP1[i]>inv$adjP2[i]){
                         # if time, adjust these amounts by the price of the stock.
                         # but given relative performance, cut losses. 
                         inv$p1states[i]=-amt
                         inv$p2states[i]=amt
                    } else{
                         inv$p1states[i]=amt
                         inv$p2states[i]=-amt
                    }
                    days.ctr=1
               }
          }
          else if(inv$p1states[i-1]!=0 && days.ctr<max.days){
               if(inv$p12sd[i]>(reg*thr)){
                    # note question stem says sell if they cross, presumably that's the threshold (vs prices).
                    inv$p1states[i]=inv$p1states[i-1]
                    inv$p2states[i]=inv$p2states[i-1]
                    days.ctr=days.ctr+1
               } else{
                    inv$trades[i]=2
                    inv$p1states[i]=0
                    inv$p2states[i]=0
                    days.ctr=0
               }
          }
          else if(days.ctr==max.days+1){
               inv$trades=2
               inv$p1states[i]=0
               inv$p2states[i]=0
               days.ctr=0
          }
          #update cash and PNL
         if(i==start){inv$p1cash[i]=inv$p2cash[i]=500}
         else{
               inv$p1cash[i]=inv$p1cash[i-1]-((1-cst)*(inv[i,1]*(inv$p1states[i]-inv$p1states[i-1])))
               inv$p2cash[i]=inv$p2cash[i-1]-((1-cst)*(inv[i,2]*(inv$p2states[i]-inv$p2states[i-1])))
          }
          inv$p1pnl[i]=inv$p1cash[i]+inv$p1states[i]*inv[i,1]
          inv$p2pnl[i]=inv$p2cash[i]+inv$p2states[i]*inv[i,2]
     }
    # return results
    if(rslt=="full"){
         return(inv)
    }
    else{
         return(sum(inv$p1pnl[i],inv$p2pnl[i]))
    }
}
```

**1. trade entry:** Trades are initiated deviation from parity exceeds the threshold amount. At that point, the stock moving down was bought and the stock moving up was sold.  

**2. trade exit:**  The strategy resulted in 142 total trades. Average holding period was significantly longer than prior models. Trades were exited after the stock valued re-converged by a regression or "retreat" amount from ther initial values. If prices did not re-converge, the trades were exited at 20 days. The first set of plots below show the adjusted price series and parity deviation over time. The second set shows trade states, cash and pnl balances. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

#all.dist=gen_distance("b",price[,2:3],start.date,mnths,"pnl")
#all.bst.dist=all.dist[which.max(all.dist[,6]),];all.bst.dist
## reconfigure settings: version=b, thr=1.7, reg=0.5, pnl=1741
all.plot=gen_distance("b",price[,2:3],start.date,mnths,"full")
rslt=gen_returns(price,all.plot,start.date,end.date)
print(rslt$port.val);print(rslt$port.v.bh)

```

**3. results (pnl):** Pairs Distance underperformed the buy-and-hold benchmark grossing $1,741, a $121 loss.

**4. results (performance ratios):** Not suprisingly, it's portfolio performance measures lagged that of the buy-and-hold model. However, it did have better treynor performance suggesting better beta-adjusted performance. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

print(rslt$port.ratios);print(rslt$bh.ratios)

```

#### b. cointegration
This section implements two approaches to cointegration. Specifically, it can operate in a OLS mode arriving at coefficients using regression, or it can use the Johansen Procedure for VAR. The code searches over a grid of threshold, regression or "retreat" values and lookback periods. The latter was used to test the sensitivity of the cointegration parity and weight deviation to different time periods.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

gen_coint=function(vrs,m,start.date,mnths,output){ #vrs: "joh","ols","avg"
     
     cst=c(0.001) # cost
     thr=seq(2,2,0.1) # threshold
     reg=seq(0.5,0.5,0.1) # allowance for regression
     lag=seq(2,2,1) # lookback period
     
     amt=50
     
     # need lookback window adjustment
     for(r in 1:length(reg)){
          for(k in 1:length(thr)){
               for(l in 1:length(lag)){
                    inv=calc_parity(vrs,m,start.date,mnths,lag[l])
                    gl=coint(inv,thr[k],reg[r],amt,output,cst) #"pnl" or "full"
                    rslt=cbind(vrs,thr[k],reg[r],lag[l],cst,gl)
                    if(exists("mstr")){mstr=rbind(mstr,rslt)}else{mstr=rslt} 
               }
          }
     }
     return(mstr)
}
# if time, adjust lookback period. also, apply lookback logic to #2. just change interval to weeks
calc_parity=function(vrs,m,start.date,mnths,lag){
     for(i in 1:mnths){
          
          cur.date=update(start.date,day=1)+months(i-1)
          lb.date=update(cur.date,day=1)-months(lag)
          inv.date=update(cur.date,day=1)+months(1)
          lb=m[paste0(lb.date,"/",cur.date-1)]
          inv=m[paste0(cur.date,"/",inv.date-1)]
          
          inv=as.data.frame(coredata(inv))
          
          # calc lookback weight
          p2.coef.ols=abs(summary(lm(lb[,1]~lb[,2]))$coefficients[2,1]) # ols p2 coef.
          var.ord=try(VARorder(lb,output=F)$aicor,silent=TRUE) # vector autoregressive lag
          if(!inherits(var.ord,"try-error")){
               if(!is.na(var.ord) && var.ord>1){ #&& var.ord<6
                    #smry=ca.jo(lb,K=var.ord,ecdet=c("none"))
                    smry=ca.jo(lb)
                    p2.coef.joh=abs(cajorls(smry,r=1)$beta[2,1])
                    #p2.coef.joh=abs(summary(ca.jo(lb,K=var.ord,ecdet=c("none")))@V[2,1]) # Johansen
               } else{p2.coef.joh=p2.coef.ols}
          } else{p2.coef.joh=p2.coef.ols}
          p2.coef.avg=sum(p2.coef.joh,p2.coef.ols)/2
          lb$adjP1=log(lb[,1]);lb$adjP2=log(lb[,2])
          if(vrs=="joh"){lb$wt=lb$adjP1-(lb$adjP2*p2.coef.joh)}
          else if(vrs=="ols"){lb$wt=lb$adjP1-(lb$adjP2*p2.coef.ols)}
          else if(vrs=="avg"){lb$wt=lb$adjP1-(lb$adjP2*p2.coef.avg)}
          lb.wtMean=colMeans(lb$wt)
          lb.wtSd=sd(lb$wt)
          
          # calc current deviations
          inv$adjP1=log(inv[,1]);inv$adjP2=log(inv[,2])
          if(vrs=="joh"){inv$curWt=inv$adjP1-(inv$adjP2*p2.coef.joh);inv$coef=abs(p2.coef.joh)}
          else if(vrs=="ols"){inv$curWt=inv$adjP1-(inv$adjP2*p2.coef.ols);inv$coef=abs(p2.coef.ols)}
          else if(vrs=="avg"){inv$curWt=inv$adjP1-(inv$adjP2*p2.coef.avg);inv$coef=abs(p2.coef.avg)}
          inv$lbWt=lb.wtMean
          inv$dev=inv$curWt-lb.wtMean
          inv$p12sd=abs(inv$dev)/lb.wtSd

          inv$p1states=0;inv$p2states=0;inv$p1cash=0;inv$p2cash=0;
          inv$p1pnl=0;inv$p2pnl=0;inv$trades=0
          for(l in 1:dim(inv)[2]){inv[,l]=as.numeric(inv[,l])};start=2;max.days=20
          
          if(exists("mstr")){mstr=rbind(mstr,inv)}else{mstr=inv}
     }
     plot_series(cbind(mstr$adjP1,mstr$adjP2),0,0,"adjusted price",
                      mstr$dev,0,0,"weight deviation")
     return(mstr)
}

coint=function(inv,thr,reg,amt,rslt="pnl",cst=0){
     start=2;max.days=20
     
     for (i in start:(dim(inv)[1]-1)){
          if (i==start){inv$p1states[i]=inv$p1states[i-1]}
          else if(inv$p1states[i-1]==0){
               if(inv$p12sd[i]>thr){
                    inv$trades[i]=2
                    p1.amt=100*(1*amt)/((1+inv$coef[i])*amt)
                    p2.amt=100*(inv$coef[i]*amt)/((1+inv$coef[i])*amt)
                    #p1.amt=amt;p2.amt=amt
                    if((inv$adjP1[i])>(inv$adjP2[i])){ 
                         inv$p1states[i]=-p1.amt 
                         inv$p2states[i]=p2.amt
                    } else{
                         inv$p1states[i]=p1.amt 
                         inv$p2states[i]=-p2.amt
                    }
                    days.ctr=1
               }
          }
          else if(inv$p1states[i-1]!=0 && days.ctr<max.days){
               if(inv$p12sd[i]>(reg*thr)){
                    inv$p1states[i]=inv$p1states[i-1]
                    inv$p2states[i]=inv$p2states[i-1]
                    days.ctr=days.ctr+1
               } else{
                    inv$trades[i]=2
                    inv$p1states[i]=0
                    inv$p2states[i]=0
                    days.ctr=0
               }
          }
          else if(days.ctr==max.days+1){
               inv$trades=2
               inv$p1states[i]=0
               inv$p2states[i]=0
               days.ctr=0
          }
          #update cash and PNL
         if(i==start){inv$p1cash[i]=inv$p2cash[i]=500}
         else{
               inv$p1cash[i]=inv$p1cash[i-1]-((1-cst)*(inv[i,1]*(inv$p1states[i]-inv$p1states[i-1])))
               inv$p2cash[i]=inv$p2cash[i-1]-((1-cst)*(inv[i,2]*(inv$p2states[i]-inv$p2states[i-1])))
          }
          inv$p1pnl[i]=inv$p1cash[i]+inv$p1states[i]*inv[i,1]
          inv$p2pnl[i]=inv$p2cash[i]+inv$p2states[i]*inv[i,2]
     }
    # return results
    if(rslt=="full"){
         return(inv)
    }
    else{
         return(sum(inv$p1pnl[i],inv$p2pnl[i]))
    }
}

```

**1. trade entry:** Trades are initiated deviation from parity exceeds the threshold amount. At that point, the stock moving down was bought and the stock moving up was sold.  

**2. trade exit:**  The strategy resulted in 160 total trades. Average holding period was significantly longer than prior models. Trades were exited either after stock values re-converged or in 20 days.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='hide',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}
#all.coint=gen_coint("joh",price[,2:3],start.date,mnths,"pnl")
#all.bst.coint=all.coint[which.max(all.coint[,6]),];all.bst.coint
## reconfigure settings: version="ols", thr=2, reg=0.5, lb=2, pnl=2174
## conforming: "ols", thr=1.7, reg=0.5, lb=3, pnl 1873
all.plot=gen_coint("ols",price[,2:3],start.date,mnths,"full")
rslt=gen_returns(price,all.plot,start.date,end.date)
print(rslt$port.val);print(rslt$port.v.bh)

```

**3. results (pnl):** The cointegration model grossed $2,174, a pickup of $311 on the buy-and-hold strategy. 

**4. results (performance ratios):** The cointegration model outperformed on most performance metrics with pickups in treynor and calmar incidating higher beta-adjusted return and performance against maximum draw-down.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

print(rslt$port.ratios);print(rslt$bh.ratios)

```

### problem 4

This section implements the trivariate co-integration strategy. It finds parity between SPY, JPM and WFC via either the Johansen or OLS method. It then flags deviations from parity initiating trades in proportion to the respective stops stationary representation. The model implements a variable moving window, threshold deviation measurement and regression or "retreat" value to govern trade exit. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='hide',warning=FALSE,fig.show='asis',fig.height=4,fig.width=7}

gen_trinity=function(vrs,m,start.date,mnths,output){ #vrs: "joh","ols","avg"
     
     cst=c(0.001) # cost
     thr=seq(1.9,1.9,0.1) # threshold
     reg=seq(0.55,0.55,0.1) # allowance for regression
     lag=seq(1,1,1) # lookback period
     
     amt=50
     
     # need lookback window adjustment
     for(r in 1:length(reg)){
          for(k in 1:length(thr)){
               for(l in 1:length(lag)){
                    inv=calc_trinity(vrs,m,start.date,mnths,lag[l])
                    gl=trinity(inv,thr[k],reg[r],amt,output,cst) #"pnl" or "full"
                    rslt=cbind(vrs,thr[k],reg[r],lag[l],cst,gl)
                    if(exists("mstr")){mstr=rbind(mstr,rslt)}else{mstr=rslt} 
               }
          }
     }
     return(mstr)
}

calc_trinity=function(vrs,m,start.date,mnths,lag){
     for(i in 1:mnths){
          
          cur.date=update(start.date,day=1)+months(i-1)
          lb.date=update(cur.date,day=1)-months(lag)
          inv.date=update(cur.date,day=1)+months(1)
          lb=m[paste0(lb.date,"/",cur.date-1)]
          inv=m[paste0(cur.date,"/",inv.date-1)]
          
          inv=as.data.frame(coredata(inv))
          
          # calc lookback weight
          p2.coef.ols=summary(lm(lb[,1]~lb[,2]+lb[,3]))$coefficients[2,1] # abs?
          p3.coef.ols=summary(lm(lb[,1]~lb[,2]+lb[,3]))$coefficients[3,1] # abs?
          
          smry=ca.jo(lb)
          p2.coef.joh=cajorls(smry,r=1)$beta[2,1]
          p3.coef.joh=cajorls(smry,r=1)$beta[3,1]
          
          lb$adjP1=log(lb[,1]);lb$adjP2=log(lb[,2]);lb$adjP3=log(lb[,3])
          if(vrs=="joh"){lb$wt=lb$adjP1-(lb$adjP2*p2.coef.joh)-(lb$adjP3*p3.coef.joh)}
          else{lb$wt=lb$adjP1-(lb$adjP2*p2.coef.ols)-(lb$adjP3*p3.coef.ols)}
          
          lb.wtMean=colMeans(lb$wt)
          lb.wtSd=sd(lb$wt)
          
          # calc current deviations
          inv$adjP1=log(inv[,1]);inv$adjP2=log(inv[,2]);inv$adjP3=log(inv[,3])
          if(vrs=="joh"){
               inv$curWt=inv$adjP1-(inv$adjP2*p2.coef.joh)-(inv$adjP3*p3.coef.joh)
               inv$p2coef=abs(p2.coef.joh);inv$p3coef=abs(p3.coef.joh)
          }
          else{
               inv$curWt=inv$adjP1-(inv$adjP2*p2.coef.ols)-(inv$adjP3*p3.coef.ols)
               inv$p2coef=abs(p2.coef.ols);inv$p3coef=abs(p3.coef.ols)
          }
          inv$lbWt=lb.wtMean
          inv$dev=inv$curWt-lb.wtMean
          inv$p12sd=abs(inv$dev)/lb.wtSd

          inv$p1states=0;inv$p2states=0;inv$p3states=0;
          inv$p1cash=0;inv$p2cash=0;inv$p3cash=0;
          inv$p1pnl=0;inv$p2pnl=0;inv$p3pnl=0;inv$trades=0
          for(l in 1:dim(inv)[2]){inv[,l]=as.numeric(inv[,l])};start=2;max.days=20
          
          if(exists("mstr")){mstr=rbind(mstr,inv)}else{mstr=inv}
     }
     par(mfrow=c(2,1))
     plot(mstr$adjP1,col="darkgreen",ylim=c(3,5.5),type="l",main="adjusted prices")
     lines(mstr$adjP2,col="red")
     lines(mstr$adjP3,col="blue")
     legend("topleft",legend=c("spy","wfc","jpm"),lwd=2,cex=1,col=c("darkgreen","red","blue"))
     plot(mstr$dev,main="weight deviation",type="l")
     return(mstr)
}

trinity=function(inv,thr,reg,amt,rslt="pnl",cst=0){
     start=2;max.days=20
     
     for (i in start:(dim(inv)[1]-1)){
          if (i==start){inv$p1states[i]=inv$p1states[i-1]}
          else if(inv$p1states[i-1]==0){
               if(inv$p12sd[i]>thr){
                    inv$trades[i]=2
                    p1.amt=100*(1*amt)/((1+inv$p2coef[i]+inv$p3coef[i])*amt)
                    p2.amt=100*(inv$p2coef[i]*amt)/((1+inv$p2coef[i]+inv$p3coef[i])*amt)
                    p3.amt=100*(inv$p3coef[i]*amt)/((1+inv$p2coef[i]+inv$p3coef[i])*amt)
                    #p1.amt=amt;p2.amt=amt
                    if(inv$adjP1[i]>inv$adjP2[i]){ 
                         inv$p1states[i]=p1.amt
                         inv$p2states[i]=-p2.amt
                         inv$p3states[i]=-p3.amt
                    } else{
                         inv$p1states[i]=-p1.amt
                         inv$p2states[i]=p2.amt
                         inv$p2states[i]=p3.amt
                    }
                    days.ctr=1
               }
          }
          else if(inv$p1states[i-1]!=0 && days.ctr<max.days){
               if(inv$p12sd[i]>(reg*thr)){
                    inv$p1states[i]=inv$p1states[i-1]
                    inv$p2states[i]=inv$p2states[i-1]
                    inv$p3states[i]=inv$p3states[i-1]
                    days.ctr=days.ctr+1
               } else{
                    inv$trades[i]=2
                    inv$p1states[i]=0
                    inv$p2states[i]=0
                    inv$p3states[i]=0
                    days.ctr=0
               }
          }
          else if(days.ctr==max.days+1){
               inv$trades=3
               inv$p1states[i]=0
               inv$p2states[i]=0
               inv$p3states[i]=0
               days.ctr=0
          }
          #update cash and PNL
         if(i==start){inv$p1cash[i]=inv$p2cash[i]=inv$p2cash[i]=500}
         else{
               inv$p1cash[i]=inv$p1cash[i-1]-((1-cst)*(inv[i,1]*(inv$p1states[i]-inv$p1states[i-1])))
               inv$p2cash[i]=inv$p2cash[i-1]-((1-cst)*(inv[i,2]*(inv$p2states[i]-inv$p2states[i-1])))
               inv$p3cash[i]=inv$p3cash[i-1]-((1-cst)*(inv[i,3]*(inv$p3states[i]-inv$p3states[i-1])))
          }
          inv$p1pnl[i]=inv$p1cash[i]+inv$p1states[i]*inv[i,1]
          inv$p2pnl[i]=inv$p2cash[i]+inv$p2states[i]*inv[i,2]
          inv$p3pnl[i]=inv$p3cash[i]+inv$p3states[i]*inv[i,3]
     }
    # return results
    if(rslt=="full"){
         return(inv)
    }
    else{
         return(sum(inv$p1pnl[i],inv$p2pnl[i],inv$p3pnl[i]))
    }
}

```

**1. trade entry:** Trades are initiated deviation from parity exceeds the threshold amount. At that point, the stock(s) moving down are bought and the stock(s) moving up are sold.  

**2. trade exit:**  Trades were exited either after stock values re-converged or in 20 days.

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

#all.trinity=gen_trinity("joh",price,start.date,mnths,"pnl")
#all.bst.trinity=all.trinity[which.max(all.trinity[,6]),];all.bst.trinity
## reconfigure settings: version="ols", thr=1.9, reg=0.55, lb=1, 2609; "joh" 1.8, 1, 3 1825
all.plot=gen_trinity("ols",price,start.date,mnths,"full")
rslt=gen_returns(price,all.plot,start.date,end.date)
print(rslt$port.val);print(rslt$port.v.bh)

```

**3. results (pnl):** The cointegration model using OLS grossed $2,609, a pickup of $746 on the buy-and-hold strategy. The Johansen model grossed $1,825, roughly inline with buy-and-hold.

**4. results (performance ratios):** The OLS model shows improvements in all ratios. It is comprehensively better model than buy-and-hold for this data. 

```{r eval=TRUE,cache=TRUE,echo=FALSE,message=FALSE,results='markup',warning=FALSE,fig.show='asis',fig.height=6,fig.width=7}

print(rslt$port.ratios);print(rslt$bh.ratios)

```
